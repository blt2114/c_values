{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "import pandas as pd\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tilde_theta_norm_upper_bound(Y, alpha=0.05):\n",
    "    tilde_Y_norm = sum((Y-np.mean(Y))**2)\n",
    "    df = Y.shape[0]-1\n",
    "    if stats.chi2.cdf(tilde_Y_norm, df) < alpha: return 1e-5\n",
    "    return optimize.newton(\n",
    "        func=lambda lmbda: stats.ncx2(df, lmbda).cdf(tilde_Y_norm)-alpha,\n",
    "        x0=max([1e-4,tilde_Y_norm-df]),\n",
    "        tol=1e-4)\n",
    "\n",
    "def b_bayes(Y, alpha, tau):\n",
    "    upper = tilde_theta_norm_upper_bound(Y, (1-alpha)/2)\n",
    "    tilde_Y_norm = sum((Y-np.mean(Y))**2)\n",
    "    g = 1/(1+tau**2)\n",
    "    N = len(Y)\n",
    "    offset = - ((g/2)*upper + (g**2)*tilde_Y_norm  )\n",
    "    ncChi2_quantile = stats.ncx2(\n",
    "        N-1,\n",
    "        (1./4.)*upper).ppf((1-alpha)/2)\n",
    "    ncChi2_term = 2*g*ncChi2_quantile\n",
    "    bya = offset + ncChi2_term\n",
    "    return bya, upper\n",
    "\n",
    "def c_value(Y, tau):\n",
    "    bya = lambda alpha: b_bayes(Y, alpha, tau)[0]\n",
    "    c_lower_bound =  1e-10\n",
    "    if bya(c_lower_bound) < 0: return c_lower_bound\n",
    "    if bya(1.-c_lower_bound) > 0: return 1.\n",
    "\n",
    "    c_val = optimize.bisect(\n",
    "        f=lambda alpha: bya(alpha),\n",
    "        a=c_lower_bound, b=1.-c_lower_bound,xtol=1e-3)\n",
    "    return c_val\n",
    "\n",
    "def where_bya_breaks(win, Y, tau):\n",
    "    bya = lambda alpha: b_bayes(Y, alpha, tau)[0]\n",
    "    c_lower_bound =  1e-10\n",
    "    if win>bya(c_lower_bound): return c_lower_bound\n",
    "    if win<bya(1.-c_lower_bound): return 1.-c_lower_bound\n",
    "    \n",
    "    where_breaks = optimize.bisect(\n",
    "        f=lambda alpha: bya(alpha)-win,\n",
    "        a=c_lower_bound, b=1.-c_lower_bound, xtol=1e-3)\n",
    "    return where_breaks\n",
    "    \n",
    "def W_lower_bound_with_norm(Y, tilde_theta_norm, tau, alpha=0.05):\n",
    "    tilde_Y_norm = sum((Y-np.mean(Y))**2)\n",
    "    g = 1/(1+tau**2)\n",
    "    N = len(Y)\n",
    "    \n",
    "    offset = - ((g/2)*tilde_theta_norm + (g**2)*tilde_Y_norm  )\n",
    "    ncChi2_quantile = stats.ncx2(\n",
    "        N-1,\n",
    "        (1./4.)*tilde_theta_norm).ppf((1-alpha)/2)\n",
    "    ncChi2_term = 2*g*ncChi2_quantile\n",
    "    bya = offset + ncChi2_term\n",
    "    return bya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Risk Profile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results to report for frequentist analysis\n",
    "\n",
    "## In filename want:\n",
    "* $\\tau, N, \\|P_1^\\perp \\theta\\|$, 'frequentist_analysis',\n",
    "\n",
    "## Here we want to save out, for each $\\|P_1^\\perp \\theta\\|^2$.\n",
    "* rep, $\\|P_1^\\perp Y\\|, \\|\\hat \\theta - \\theta\\|^2, \\|\\theta^* - \\theta\\|^2, W, c(y)$\n",
    "\n",
    "\n",
    "## Processed data (function  only of earlier files), one for each $\\alpha$\n",
    "* In filename want $\\tau, N, \\alpha$, 'frequentist_analysis_summary'\n",
    "* $\\|P_1^\\perp \\theta\\|$, P_choose_bayes, P_choose_bayes_SE, Bayes_risk, Bayes_risk_SE, combined_risk, combined_risk_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_bayes_estimator(N, theta_norm, tau, n_reps=50):\n",
    "    \"\"\"combined_bayes_estimator simulates data from model with fixed theta\n",
    "    projected norm and returns the results of trials.\n",
    "    \n",
    "    Returns:\n",
    "    Py_norms, mle_errs, bayes_errs, wins, cys \n",
    "    \n",
    "    \"\"\"\n",
    "    Py_norms, c_values, wins, mle_errs, bayes_errs, by_breaks = [], [], [], [], [], []\n",
    "    \n",
    "    theta = np.random.normal(size=[N])\n",
    "    theta *= theta_norm/np.linalg.norm(theta-np.mean(theta))\n",
    "    for _ in range(n_reps):\n",
    "        Y = theta +np.random.normal(size=theta.shape)\n",
    "        tilde_Y_norm = sum((Y-np.mean(Y))**2)\n",
    "        \n",
    "        bayes = Y + (1/(1+tau**2))*(np.mean(Y)-Y)\n",
    "        mle_err, bayes_err = np.sum((Y-theta)**2), np.sum((theta-bayes)**2)\n",
    "        win, c_val = mle_err - bayes_err, c_value(Y, tau)\n",
    "        \n",
    "        # compute alpha below which bound fails to hold\n",
    "        by_break = where_bya_breaks(win, Y, tau)\n",
    "        \n",
    "        Py_norms   += [tilde_Y_norm]\n",
    "        mle_errs   += [mle_err]\n",
    "        bayes_errs += [bayes_err]\n",
    "        wins       += [win]\n",
    "        c_values   += [c_val]\n",
    "        by_breaks  += [by_break]\n",
    "    return Py_norms, mle_errs, bayes_errs, wins, c_values, by_breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7320508075688772]\n",
      "complete :  1.7320508075688772\n"
     ]
    }
   ],
   "source": [
    "# Run simulations for different values of \\| P_1^\\perp \\theta\\|\n",
    "from multiprocessing import Pool\n",
    "\n",
    "base_fn = \"../results/section3_simulation_study/\"\n",
    "def run_simulation(tau, N, theta_norm, n_reps):\n",
    "    Py_norms, mle_errs, bayes_errs, wins, c_values, by_breaks = combined_bayes_estimator(\n",
    "        N, theta_norm, tau, n_reps=n_reps)\n",
    "    \n",
    "    # Write out results of simulation\n",
    "    fn_out = base_fn + \"tau=%0.02f_N=%03d_P_theta_norm=%0.02f_frequentist_analysis.tsv\"%(tau, N, theta_norm)\n",
    "    assert not os.path.exists(fn_out)\n",
    "    \n",
    "    with open(fn_out, 'w') as f:\n",
    "        f.write(\"\\t\".join([\"Rep\", \"P_Y_norm\", \"MLE_Err\", \"Bayes_Err\", \"Win\", \"c_value\", \"by_break\"]) + \"\\n\")\n",
    "        for rep, rep_vals in enumerate(zip(Py_norms, mle_errs, bayes_errs, wins, c_values, by_breaks)):\n",
    "            l = \"%04d\\t\"%rep + \"\\t\".join([\"%0.05f\"%val for val in rep_vals])+\"\\n\"\n",
    "            f.write(l)\n",
    "    print(\"complete : \", theta_norm)\n",
    "\n",
    "N, tau, n_reps = 2, 1., 5000\n",
    "theta_norm_min, theta_norm_max = 0, 1.5*np.sqrt(2*tau+2)*np.sqrt(N-1)\n",
    "theta_norms = list(np.arange(theta_norm_min,theta_norm_max,(theta_norm_max-theta_norm_min)/20))\n",
    "\n",
    "theta_norms = [np.sqrt((2*tau**2 + 1)*(N-1))]\n",
    "print(theta_norms)\n",
    "\n",
    "n_workers = 4\n",
    "def f(theta_norm): run_simulation(tau, N, theta_norm, n_reps)\n",
    "with Pool(n_workers) as p: p.map(f, theta_norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize results for combined estimator at different alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequentist_summary(mle_errs, bayes_errs, c_values, alpha):\n",
    "    \"\"\"frequentist_summary returns a summary of the combined estimator\n",
    "    on the replicates provided for the given choice of alpha.\n",
    "    \"\"\"\n",
    "    n_reps = len(mle_errs)\n",
    "    chose_bayes = c_values>=alpha\n",
    "    \n",
    "    # estimate frequency at which combined estimator evaluates to the Bayes estimate.\n",
    "    P_choose_bayes = np.mean(chose_bayes)\n",
    "    P_choose_bayes_SE = np.sqrt(P_choose_bayes*(1-P_choose_bayes))/np.sqrt(n_reps)\n",
    "    \n",
    "    # estimate risk of bayes and combined estimators\n",
    "    Bayes_risk = np.mean(bayes_errs)\n",
    "    Bayes_risk_SE = np.std(bayes_errs)/np.sqrt(n_reps)\n",
    "    \n",
    "    combined_errs = mle_errs*(1-chose_bayes) + bayes_errs*chose_bayes\n",
    "    combined_risk = np.mean(combined_errs)\n",
    "    combined_risk_SE = np.std(combined_errs)/np.sqrt(n_reps)\n",
    "    \n",
    "    return P_choose_bayes, P_choose_bayes_SE, Bayes_risk, Bayes_risk_SE, combined_risk, combined_risk_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out results of simulation\n",
    "alphas = np.array([0.1,0.5, 0.75,0.8, 0.85, 0.9, 0.95, 0.975, 0.99, 0.995])\n",
    "for alpha in alphas:\n",
    "    fn_out = base_fn + \"tau=%0.02f_N=%03d_alpha=%0.03f_frequentist_analysis_summary.tsv\"%(tau, N, alpha)\n",
    "    assert not os.path.exists(fn_out)\n",
    "    with open(fn_out, 'w') as f:\n",
    "        f.write(\"\\t\".join([\"P_theta_norm\", \"P_choose_bayes\", \"P_choose_bayes_SE\", \"Bayes_risk\", \"Bayes_risk_SE\",\n",
    "                           \"combined_risk\", \"combined_risk_SE\"])+\"\\n\")\n",
    "        for theta_norm in theta_norms:\n",
    "            fn_in = base_fn+\"tau=%0.02f_N=%03d_P_theta_norm=%0.02f_frequentist_analysis.tsv\"%(tau, N, theta_norm)\n",
    "            df = pd.read_csv(fn_in, sep=\"\\t\")\n",
    "            mle_errs, bayes_errs, c_values = df.MLE_Err, df.Bayes_Err, df.c_value\n",
    "            summary_stats = list(frequentist_summary(mle_errs, bayes_errs, c_values, alpha))\n",
    "            f.write(\"\\t\".join(\"%0.02f\"%v for v in ([theta_norm]+summary_stats))+ \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
